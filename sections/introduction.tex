\section{Introduction}
\label{sec:intro}


Optimization parameters such as tile sizes and loop unrolling factors are critical to performance and it
is crucial to estimate the optimal value during optimization.
Currently programmers usually rely on optimization techniques provided by traditional compilers, which
is often too generalized to yield desired performance.
General compiler techniques cannot take care of applications such as general matrix multiply(GEMM),
whose performance is heavily based on those optimization parameters.
On the other hand, writing highly optimized code is impractical for average
programmers because it requires huge amount of prior knowledge both for application
itself and the target platform.


%Optimization parameters of high performance programs must be tuned for a given platform.
%how the program is written and how the optimization parameter is set.
\par

Auto-tuning is a straight-forward and one of the simplest ways to find the optimal parameters.
There are two major categories of auto-tuning approaches: exhaustive search and model-based search.
\par
Exhaustive search tries to find out the parameter setting with the best
performance by actively searching every parameter setting in
the design space. All the parameter settings are evaluated and compared by
actual execution.
This technique has been successfully applied to build a variety
of high-performance domain-specific libraries including
dense linear algebra \cite{whaley2001automated, bilmes2014optimizing},
sparse linear algebra \cite{vuduc2005oski}, signal processing
\cite{frigo2005design, puschel2005spiral}, sorting \cite{li2004dynamically},
general stencil operations \cite{kamil2010auto}, etc.

However, exhaustively searching the whole parameter space is slow and usually
impractical for most of high performance computing applications.
The search space is usually too large and the evaluation of parameter settings
with low performance takes much more time ironically.
Consequently, exhuastive search can only be applied to problems with small
optimization space or already pruned spaces.

The second category of auto-tuning is model-based tuning. This kind of methods
usually builds an analytical model to estimates optimal parameters.
The significant advantage of such approach is fast. Good optimization
parameters can be directly derived from the analytical model.
However, it is generally difficult to build a highly accurate analytical model
in practice because of the growing complexity of modern architectures and
applications. The analytical model is too platform dependent and application
specific for practical use.

It is intuitive to come up with the idea that somehow combines the two
approaches together by first pruning the search space with an automatically
generated model, and then evaluating the pruned search space by exhaustive
search. On the other hand, users are not willing
to wait for a day or two, or even an hour to get the most optimized result in
most cases. An ``good enough'' result is adequate. Therefore, approximation can
be introduced to accelerate the optimization process.

There is growing interest in approximate computing as a way of reducing energy
and time required to execute applications. \cite{ansel2011language,
baek2010green, sidiroglou2011managing, swaminathan2015case}. In conventional
computing, programs are usually treated as implementations of mathematical
functions, so there is a precise output for a given input.
However, in many problem domains, it is sufficient to produce an good ``enough''
result: for example, when rendering a image in graphics, it is
acceptable to take computational short-cuts if the graph doesn't hurt user's
experience. In addition, since analytical models are often imprecise for
applications with high complexity. Machine learning models can be a great
substitute. In this paper, we use Capri\cite{sui2016proactive}, a published
approximate software, to build machine learning based models for \gem
performance. We denote parameter settings as knobs or knob settings in
our paper. Capri would take past \atl running data and produce a machine
learning based model. \atl search process would take few top candidate knobs
generated by Capri and provide users with the best knob among the candidates
knobs by evaluating them exhaustively.

The contributions of this papers are:
\begin{itemize}
\item The performance of \gem can be well modeled by machine learning based
models provided by Capri.
\item The proposed Capri-based \atl can speed up the optimization process by 10X.
\item The performance of \gem using the knobs generated by Capri-based \atl
has average of 2\% performance degradation compared to the exhaustive search,
while the original \atl suffers 13\% performance degradation.
\end{itemize}

\par
The rest of this paper is organized as follows. Section \ref{sec:background}
describes the background of ATLAS tuning strategy and Capri approximate
software. Section \ref{sec:design} introduces the design of Capri-based
ATLAS search.
Section \ref{sec:experiment} provides the details of experiment methodology.
Section \ref{sec:evaluation} shows all the experiment results of our system,
analyzing and comparing them with the original ATLAS result.
Section \ref{sec:related} provides an overview of related work.
And finally, section \ref{sec:conclusion} concludes and outlines our possible
future work.
