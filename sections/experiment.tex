\section{Experiment Methodology}
\label{sec:experiment}
\begin{figure*}[tbhp]
  \centering
  \includegraphics[width=0.9\textwidth]{images/platforms.png}
  \caption{Platforms profiled in this paper}
  \label{fig:platforms}
\end{figure*}

In the experiment, we only consider single precision, real number \gem because
of the limitation of time.

At the \atl part, we implement an exhaustive search moduel that takes a user
defined range of knobs setting as input on ATLAS.
The space of each knob is chosen as follows.
\begin{itemize}
\item $NB$: Multiple of 4 in range $[20, 80]$
\item $MU$,$NU$: $\{1, 2, 3, 4, 5, 6, 8, 10, 12\}$ for 16 registers, \{4, 6, 8, 10, 12, 14, 16, 24, 32\} for 32 registers
\item $KU$: $\{1, 2, 3, 4, 5, 6, 8, 10, 12, NB\}$
\end{itemize}
The exhaustive search tries every possible combination of them.
On a typical platform as we mentioned in Section \ref{sec:atlas_intro}, it takes more than 10 hours to finish
the search on 12960 data points.\par

We carefully pick 12 platforms to evaluate our system, as lised in Figure \ref{fig:platforms}. \textit{arma7} and \textit{arma15}
are two ARM Cortex processors on an ODROID board.
\textit{ypei\_mac} and \textit{michael\_mac} are two personal MAC laptops
with Intel CORE i7 processors. The rest eight platforms are machines of ICES or CS department, whose processors are all produced by intel.

Note that the third column \textit{architecture} is provided by ATLAS configuration process.
ATLAS identifies this information but does not use it in the orthogonal search procedure. Instead, after automatically
generating high performance code, ATLAS compares it with existing hand-tuned unleashed codes which has been included in the system,
and pick the best. Those hand-written codes are categorized according to this \textit{architecture}.
We adopt it as one of our training set grouping metric in the experiment.\par


In the experiment, we train the model offline from a training set of platforms, and get the top ten knob settings generated from the model.
We evaluate these ten knob settings on another target platform and compare them with the best of exhaustive search. We select
three categories of training sets. 1) ALL. 2) ``Corei'' architecture group. This group contains all the platforms
with intel processors except two mac platform 3) Specific architecture group.
We categorize the platform specifically according to the architecture or compilers. Each architecture or compiler corresponds to a group and we only use data from the exact same architecture to train. All the performance are modeled by 3 different models, including M5, bagging predictor and extremely randomized tree from Capri.

Performance(MFLOPS) of the generated kernel and search(tuning) time are monitored in order to evaluate our system.
